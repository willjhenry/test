{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro To Reading Data From A Database Into A Pandas DataFrame (and how to install packages)\n",
    "\n",
    "A common and popular data access pattern, with Pandas, is to query data from a database directly into a Pandas DataFrame.  Once the data is in the DataFrame, a user can further analyze the data. In this notebook, I give examples of how to read data from a PostgreSQL database and a MySQL database.\n",
    "\n",
    "To read data from a database into a pandas DataFrame, use SQLAlchemy, which is installed with Anaconda, to create an Engine object which will be the \"bridge\" between pandas and the database. SQLAlchemy supports multiple drivers for different databases, but requires that you have the driver, you want to use, installed.\n",
    "\n",
    "See examples in the SQLAlchemy documentation here: (http://docs.sqlalchemy.org/en/latest/core/engines.html)\n",
    "\n",
    "Some example drivers, for different databases are as follows:\n",
    "\n",
    "* MySQL: pymysql, mysqldb\n",
    "* PostgresSQL: psycopg2, pg8000\n",
    "* Microsoft SQL Server: pyodbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the necessary driver\n",
    "\n",
    "Before we can use SQLAlchemy, we must install the necessary driver for the database we wish to connect to. Often, these can be installed in the form of python packages (even if the package includes drivers in non-python, compiled languages. Conda takes care of these complexities for us)\n",
    "\n",
    "There are *three* ways we can install python packages:\n",
    "\n",
    "* We can use the anaconda-navigator\n",
    "* We can use \"conda install <package-name>\" from the terminal or anaconda prompt\n",
    "* We can use \"pip install <package-name>\" from the terminal or anaconda prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Connecting to a MySQL database using the pymysql driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# import pymysql  # driver for MySQL connections\n",
    "# import psycopg2  # driver for PostgreSQL connections\n",
    "# import pyodbc # driver you can use for Google Big Query, Hive, MySQL, PostgresSQL, Microsoft SQL Server, and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Form the correct database url\n",
    "\n",
    "The format for the database url is: dialect+driver://username:password@host:port/database\n",
    "\n",
    "the format is: dialect+driver://username:password@host:port/database\n",
    "\n",
    "* example for MySQL: \"mysql+pymysql://test:123@132.148.86.167:3306/mydatabase\" \n",
    "\n",
    "* example for PostgreSQL: \"postgresql+psycopg2://admin:secret123@145.134.99.167:3306/database\" \n",
    "\n",
    "* example for Microsoft SQL Server: \"mssql+pyodbc://scott:tiger@ms_2008/mydb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = \"mysql+pymysql://test:123@132.148.86.167:3306/mydatabase\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create the database \"engine\" use create_engine from sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Query the database using the read_sql() method from pandas (and pass the engine you created above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM ShiftManagerApp_LaborSheet'\n",
    "dataframe_with_query_results = pd.read_sql(sql, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about other databases??\n",
    "\n",
    "## I have yet to hear of a database that python can not connection to...\n",
    "\n",
    "* AWS: https://aws.amazon.com/sdk-for-python/\n",
    "* Oracle: https://www.oracle.com/technetwork/articles/dsl/python-091105.html\n",
    "* PyHive: https://community.hortonworks.com/articles/97062/query-hive-using-python.html\n",
    "* MongoDB: https://docs.mongodb.com/ecosystem/drivers/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question or Comments About This Notebook?\n",
    "Feel free to contact me via my LinkedIn: https://www.linkedin.com/in/william-j-henry <br>\n",
    "You can also email me at will@henryanalytics.com <br>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
