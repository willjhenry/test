{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing and Apply\n",
    "\n",
    "If you have to use `.apply()` - there is a way to use multiprocessing with `.apply()`, and this *might* speed up your results.\n",
    "\n",
    "I am very much a beginner when it comes to using multiprocessing with python and have only used it myself a few times.  Below is an example of how I have used it to improve the speed of data processing. Note that this was on a machine with 96 cores.\n",
    "\n",
    "There is much more to multiprocessing than what you see in this example. To learn more, see the guides/docs here: https://docs.python.org/3.8/library/multiprocessing.html <br>\n",
    "https://docs.python.org/3/library/concurrent.futures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from concurrent.futures import ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Multiprocessing Example\n",
    "\n",
    "In this example we have fake time series data. For 100,000 different groups. Think of it as 100,000 different temperature sensors. Each group has 5 data points. Each data point has a \"score\" value, but many of these values are null.  For each of the 100,000 time series, we need to fill the null values with the previous value, assuming the previous value is non-null.  We start from the first point in the time series and move forward.  The order of the time series is given by the \"order\" column.\n",
    "\n",
    "We create this fake data in the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Some Fake Data For This Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed so that the example is reproducable\n",
    "np.random.seed(19)\n",
    "\n",
    "N = 100000  # number of groups\n",
    "K = 5  # number of points per group\n",
    "\n",
    "group_ids = np.tile(range(0, N), K)\n",
    "order = np.concatenate([np.ones(N) + x for x in range(5)])\n",
    "\n",
    "scores = np.ones_like(group_ids) * np.nan\n",
    "scores[np.random.randint(0, len(scores), int(N*K*0.5))] = np.random.rand(int(N*K*0.5))\n",
    "\n",
    "# Comvine the group_id, order, and score columns into a dataframe\n",
    "my_data = pd.DataFrame([group_ids, order, scores]).T\n",
    "my_data.columns = ['group_id', 'order', 'score']\n",
    "my_data = my_data.sample(frac=1).reset_index(drop=True)\n",
    "my_data['group_id'] = my_data['group_id'].astype(int)\n",
    "my_data.sort_values(by=[\"group_id\", \"order\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>order</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73653</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51522</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.667212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124104</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43731</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.416135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287132</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.225123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374386</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451609</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.883130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95948</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.317241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342395</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.972857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463988</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.419329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  order     score\n",
       "73653          0    1.0  0.167110\n",
       "51522          0    2.0  0.667212\n",
       "124104         0    3.0       NaN\n",
       "43731          0    4.0  0.416135\n",
       "287132         0    5.0  0.225123\n",
       "374386         1    1.0       NaN\n",
       "451609         1    2.0  0.883130\n",
       "95948          1    3.0  0.317241\n",
       "342395         1    4.0  0.972857\n",
       "463988         1    5.0  0.419329"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the data by the group id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_groups = my_data.groupby('group_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at one of the groups as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>order</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306240</th>\n",
       "      <td>1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17489</th>\n",
       "      <td>1000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454714</th>\n",
       "      <td>1000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147282</th>\n",
       "      <td>1000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.622336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497298</th>\n",
       "      <td>1000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  order     score\n",
       "306240      1000    1.0       NaN\n",
       "17489       1000    2.0       NaN\n",
       "454714      1000    3.0       NaN\n",
       "147282      1000    4.0  0.622336\n",
       "497298      1000    5.0       NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_groups.get_group(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Solution Using Apply\n",
    "\n",
    "We use the function defined below to fill the null values using the forward fill method, for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate_score(group):\n",
    "    '''Sort the values by the order column and then fill null values in the\n",
    "    score column using the forward-fill method\n",
    "    '''\n",
    "    scores_filled = group['score'].fillna(method='ffill')\n",
    "    return scores_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 29.58462405204773\n"
     ]
    }
   ],
   "source": [
    "time_1 = time.time()\n",
    "results = data_groups.apply(propogate_score)\n",
    "time_2 = time.time()\n",
    "\n",
    "print(f'Elapsed Time: {time_2 - time_1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A Solution Using Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propogate_score_mp(x):\n",
    "    g_id = x[0]\n",
    "    group = x[1]\n",
    "    scores_filled = group['score'].fillna(method='ffill')\n",
    "    return scores_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on the cell below:\n",
    "\n",
    "`Pool()` create a pool of processes, `p`, that we can send work to. The `.map_async()` method maps the function to each group in data_groups but dividing the groups up into chunks and sending them to processes in the pool. The tasks are asynchronous, meaning that our main process (our notebook) can still run while the pool is running. This is how we are able to run the while loop that keeps printing the number of tasks left. Note that once the results are ready (meaning all tasks are complete) we exit the while loop.\n",
    "\n",
    "\n",
    "#### Notice that adjust the` chunksize` can significantly impact the performance.\n",
    "The `chunksize` is the number of items in your list of items to process that are chunked together and sent to each processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 20000 tasks to complete...\n",
      "Waiting for 19374 tasks to complete...\n",
      "Waiting for 18683 tasks to complete...\n",
      "Waiting for 18281 tasks to complete...\n",
      "Waiting for 17478 tasks to complete...\n",
      "Waiting for 16706 tasks to complete...\n",
      "Waiting for 15863 tasks to complete...\n",
      "Waiting for 14977 tasks to complete...\n",
      "Waiting for 14222 tasks to complete...\n",
      "Waiting for 13361 tasks to complete...\n",
      "Waiting for 12596 tasks to complete...\n",
      "Waiting for 11833 tasks to complete...\n",
      "Waiting for 11068 tasks to complete...\n",
      "Waiting for 10151 tasks to complete...\n",
      "Waiting for 9346 tasks to complete...\n",
      "Waiting for 8651 tasks to complete...\n",
      "Waiting for 7839 tasks to complete...\n",
      "Waiting for 7185 tasks to complete...\n",
      "Waiting for 6514 tasks to complete...\n",
      "Waiting for 5743 tasks to complete...\n",
      "Waiting for 5128 tasks to complete...\n",
      "Waiting for 4332 tasks to complete...\n",
      "Waiting for 3546 tasks to complete...\n",
      "Waiting for 2717 tasks to complete...\n",
      "Waiting for 2179 tasks to complete...\n",
      "Waiting for 1417 tasks to complete...\n",
      "Waiting for 616 tasks to complete...\n",
      "Waiting for 48 tasks to complete...\n",
      "Elapsed Time: 32.09116268157959\n"
     ]
    }
   ],
   "source": [
    "time_1 = time.time()\n",
    "\n",
    "p = Pool()\n",
    "results = p.map_async(propogate_score_mp, data_groups, chunksize=5)\n",
    "p.close() # Close pool now that no more work will be submitted\n",
    "\n",
    "while (True):\n",
    "  if (results.ready()):\n",
    "    break\n",
    "  remaining = results._number_left\n",
    "  print(\"Waiting for\", remaining, \"tasks to complete...\")\n",
    "  time.sleep(1)\n",
    "\n",
    "p.join() # Block the main process untill the pool is completely terminated\n",
    "\n",
    "time_2 = time.time()\n",
    "\n",
    "results_df = pd.concat(results.get())\n",
    "\n",
    "print(f'Elapsed Time: {time_2 - time_1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question or Comments About This Notebook?\n",
    "Feel free to contact me via my LinkedIn: https://www.linkedin.com/in/william-j-henry <br>\n",
    "You can also email me at will@henryanalytics.com <br>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
